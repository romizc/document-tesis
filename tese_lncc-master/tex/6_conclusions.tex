\chapter{Conclusions and Future Works}
\label{chapter_Conclusions}

This final chapter contains the closing remarks of this work. Here, the most important contributions and findings are highlighted, with additional discussion about the methodology, the analysis, and the experiments. The chapter concludes with possible research lines that can be pursued in the future, following the direction of this work.
	
\section{Results Summary}
\label{Sec:ResultsSummary}

The main objective of our work is to develop a methodology that can be used to make predictions about future states of a spatio-temporal region, using carefully selected predictive models that have been trained with limited temporal data, but at the same time produce predictions about unseen temporal data within some tolerated error margin. The computational experiments were then designed to evaluate the proposed methodology, considering the case study of temperature prediction.

According to the proposed experiments, we can assert that the domain can be grouped according to a shape-based (temporal) measure of similarity between elements. Each of these groups is represented by a representative element that generalizes the behavior (temporal dimension) of the group. In order to describe the similarity between temporal series, the calculation of the DTW distance was used, which measures the similarity based on the temporal evolution of two elements.

The pairwise DTW distances can be expressed as a 2-d matrix. Computationally, the calculation of this matrix is an expensive process. However, this particular implementation allowed us to perform this time-consuming calculation only once and then store the result as an array for quick retrieval and query. This treatment enabled us to accelerate other processes such as the grouping of elements, effectively saving computational resources without losing any quality results.

The spatio-temporal domain is grouped based on the similarity of the temporal evolution using the $k$-medoids method. This crisp approach assigns exactly one group for each element, and at the same time, calculates one of the elements as the representative of that group. We then say that this representative generalizes the elements of its group and can be used to train useful predictive models. A second partitioning strategy based on the geometry of the domain (regular partitioning) was used as a baseline to validate the main approach based on $k$-medoids.

An important choice in the approach based on representatives is to select an adequate partitioning scheme (driven by the value of the parameter $k$) that will produce the groups and representatives. Intuitively, we expect that larger values of $k$ will yield smaller and more compact groups so that the predictive model at a representative will provide a more accurate prediction. However, the analysis of the forecast errors that were performed indicates that this is not always the case; smaller values of $k$ may offer more accurate predictive models for some of the elements.

% TODO based on... -> Neural Network Classifiers for sequential data
The previous result is the main driver of the classifier that was proposed as part of the methodology: instead of choosing a single partitioning scheme, we allow a set of partitioning schemes ($k = \lbrace 8, 66, 132 \rbrace$) and store all the corresponding predictive models. Our classifier based on a neural network classifier for sequential data can then match a subset (last $t_p$ values) of the temporal series of the element of interest with one of the representatives.

% TODO more?
To complete the case study, the `offline' process of training predictive models is evaluated with spatio-temporal predictive queries, which can be considered the `online' phase of the methodology and initiated after the training has taken place. Here, the composition method or ensemble of models leveraged to attend to elements of a specific region is a simple and fast process and therefore adequate for the online phase, which requires low response time.

% TODO numbers
% 85.1052048726467	k=8
% 15.2270210409745	k=66
% 11.4617940199336	k=132
% 45.1949058693245 Classifier (58)
The temporal predictive method used for this space-time phenomenon can present a high degree of accuracy in predicting the phenomenon if a predictive model is generated and evaluated for each element. However, this is computationally expensive and time-consuming. When compared with the approach based on representatives, we find that some predictive quality is lost when evaluating predictive queries (20\% when choosing $k=66$, 45\% when using the classifier). We conclude that our multiclass model composition can produce forecast errors comparable to a naive approach but with a computational efficiency of about two orders of magnitude greater.

\section{Main Contributions}
\label{Sec:MainContributions}

From the proposed methodology and its evaluation, we can extract the following contributions to the relevant lines of research:

\begin{enumerate}

\item \textbf{A comprehensive approach for grouping temporal elements based on their shape can calculate elements that generalize certain regions of the spatio-temporal domain.} By understanding the process of the partitioning scheme based on DTW distances, we were able to implement this step efficiently using parallelization and persistence, and therefore gain a considerable reduction in the computational resources and time required to perform the operations. With experimental analysis using another partitioning scheme as a baseline, we were able to verify the robustness of the proposed partitioning algorithm.

\item \textbf{A time series classification approach for model selection.} A novel approach for model composition in a spatio-temporal domain with high data volume, expressed as a classification problem and supported by a hybrid (machine learning). We validated this approach against a naive baseline and a simpler approach based on a single partitioning scheme. We verified that the solution is viable in an environment for online spatio-temporal predictive queries.

\item \textbf{A flexible analysis of the forecast errors produced by predictive models.} We successfully applied the same forecast error analysis for the main type of predictive model (ARIMA) and another type of model used as baseline ($k$NN). This same approach can be useful for other types of predictive models and different spatio-temporal problems.

\item \textbf{An open-source Python package designed to work with spatio-temporal data and predictive models.} This package was developed to implement a computational solution to execute the methodology described in this work. However, it can be easily adapted and extended for other similar purposes in the field of spatio-temporal analysis.
\end{enumerate}

\section{Future Works}

Here we lay out some of the possible directions for future research to extend the reach of this work.

\begin{itemize}
    
    \item Test the capacity and applicability of the proposed methodology with another dataset from a different spatio-temporal phenomenon. Here, we may consider the possibility of traffic flow, which is also characterized by univariate temporal series with spatial characteristics. The goal is to predict traffic conditions in a transportation network based on its past behavior. Improving predictive accuracy within this context would be of extreme importance to inform travelers about traffic conditions and design and realize infrastructures and mobility services and schedule interventions.
    
    \item The calculation of pairwise DTW distances was not a critical element to the performance of the use case scenario because this compute-intensive process was done only once during the offline phase. However, if we wanted to group evolving time series based on their shape (shape-based clustering), using the default Dynamic Time Warping (DTW) algorithm would not be feasible, because an aggregation of temporal data (extension of the time series) would imply calculating the whole matrix again. Here, we can analyze the possibility of using an incremental process for the DTW distance that recycles intermediate results of previous calculations for new observations \cite{Oregi2017}.
    
    \item Given that we have considered the division of the domain through a supervised learning technique, it is possible to see that given the properties of the spatio-temporal data (autocorrelation and non-static), there is a difficulty in finding an ideal number of partitions. Thus, the domain partitioning process may be extended to include non-crisp group relationships, as in fuzzy $k$-medoids \cite{Izakian2015}. Having more than one representative for a given element in the same partitioning scheme may prove useful when considering model composition. For example, it may be the case that two predictive models from different representatives could be merged into a single, more accurate predictive model.

    \item The modular design of the SPTA-TSA framework facilitates the implementation of other families of predictive models and their integration into other aspects of the methodology, such as forecast error analysis and query processing. Historically, the ARIMA models have been extensively used in fields such as climate, geophysics, econometrics, among others. However, predictive models based on neural networks are becoming increasingly prevalent for temporal series in data streaming scenarios, such as LSTM, RNN, 1DCNN \cite{Shen2020, Torres2021}. Achieving integration of these models into the existing methodology would represent an important improvement in the proposed solution, both in terms of predictive accuracy and adaptability to other domains.

    \item In the context of the case study presented in this work, the online phase characterized by query processing did not represent a significant computational effort. The ARIMA models may take some time for training, but the prediction of a single temporal series is in the order of milliseconds. However, more complex models would imply perceivable service times, and then the total response time for a given query can become significant to the user. A natural evolution for our methodology would be to include a multi-objective optimization process. Quality metrics about computational resources and response time would be factored in along with quality metrics of predictive quality. In this scenario, the user may choose between different optimized trade-offs between accuracy and effort.
\end{itemize}

%"forecast at scale"