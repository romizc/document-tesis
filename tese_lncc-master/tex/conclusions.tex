\chapter{Conclusions and Future Works}
\label{chapter_Conclusions}

This final chapter contains the closing remarks of this work. Here, the most important contributions and findings are highlighted, with additional discussion about the methodology, the analysis and the experiments. The chapter concludes with possible research lines that can be pursued in the future, following the direction of this work.
	
\section{Results Summary}
\label{Sec:ResultsSummary}

The main objective of our work is to develop a methodology that can be used to make predictions about future states of a spatio-temporal region, using carefully selected predictive models that have been trained with limited temporal data, but at the same time produce predictions about unseen temporal data within some tolerated error margin. The computational experiments were then designed to evaluate the proposed methodology, considering the case study of temperature prediction.

According to the proposed experiments, we can assert that the domain can be grouped according to a shape-based (temporal) measure of similarity between elements, and each of these groups are represented by a representative element that generalizes the behavior (temporal dimension) of the group. In order to describe the similarity between temporal series, the calculation of the DTW distance was used, which measures the similarity based on the temporal evolution of two elements.

The pairwise DTW distances can be expressed as a 2-d matrix. Computationally, the calculation of this matrix is an expensive process, but this particular implementation allowed us to perform this time consuming calculation only once, and then store the result as an array for quick retrieval and query. This treatment enabled us to accelerate other processes such as the grouping of elements, effectively saving computational resources without losing any quality in the results.

The spatio-temporal domain is grouped based on the similarity of the temporal evolution by means of the $k$--medoids method, a crisp approach that assigns exactly one group for each element, and at the same time calculates one of the elements as the representative of that group. We then say that this representative generalizes the elements of its own group, and can be used to train useful predictive models. A second partitioning strategy based on the geometry of the domain (regular partitioning) was used as a baseline to validate the main approach based on $k$--medoids. % TODO numbers kmedoids vs regular?

% TODO classifier
An important choice in the approach based on representatives, is to select an adequate partitioning scheme (driven by the value of the parameter $k$) that will produce the groups and representatives. Intuitively, we expect that larger values of $k$ will yield smaller and more compact groups so that the predictive model at a representative will provide a more accurate prediction. However, the analysis of the forecast errors that were performed indicate that this is not always the case, smaller values of $k$ may offer more accurate predictive models for some of the elements.

The previous result is the main driver of the classifier that was proposed as part of the methodology: instead of choosing a single partitioning scheme, we allow a set of partitioning schemes ($k = \lbrace 8, 66, 132 \rbrace$) and store all the corresponding predictive models. Our classifier based on TODO is then able to match a subset (last $t_p$ values) of the temporal series of the element of interest, with one of the representatives. %With this approach, it was possible to obtain a perceivable improvement over the partitioning scheme with the largest value of $k$ ($k = 132$).

% TODO more?
To complete the case study, the `offline' process of training predictive models is evaluated with spatio-temporal predictive queries, which can be considered the `online' phase of the methodology and initiated after the training has taken place. Here, the composition method or ensemble of models leveraged to attend to elements of a specific region, is a simple and fast process and therefore adequate for the online phase which requires low response time.

% TODO numbers
The temporal predictive method used for this space-time phenomenon can present a high degree of accuracy in predicting the phenomenon, if a predictive model is generated and evaluated for each element. However, this is computationally expensive and time consuming. When compared with the approach based on representatives, we find that some predictive quality is lost when evaluating predictive queries (X\% when choosing $k=K$, Y\% when using the classifier). We conclude that our multiclass model composition can produce forecast errors comparable to a naive approach, but with a computational efficiency of about two orders of magnitude greater.

\section{Main Contributions}
\label{Sec:MainContributions}

From the proposed methodology and its evaluation, we can extract the following contributions to the relevant lines of research:

\begin{enumerate}
\item \textbf{A formal description of how a spatio-temporal predictive query can be processed using a composition of predictive models.} This formalization has enabled us to adequately and consistently describe the different processes and components involved in the proposed methodology, and corresponding flow of data.

\item \textbf{A comprehensive approach for grouping temporal elements based on their shape, that is able to calculate elements that generalize certain regions of the spatio-temporal domain.} By understanding the process of the partitioning scheme based on DTW distances, we were able to implement this step efficiently using parallelization and persistence, and therefore gain a considerable reduction in the computational resources and time required to perform the operations. With experimental analysis using another partitioning scheme as a baseline, we were able to verify the robustness of the proposed partitioning algorithm.

% TODO acomodar una frase para intro?
\item A novel approach for model composition in a spatio-temporal domain with high data volume, expressed as a classification problem and supported by a hybrid (machine learning). We validated this approach against a naive baseline and a simpler approach based on a single partitioning scheme, and verified that the solution is viable in an environment for online spatio-temporal predictive queries.

\item \textbf{A flexible analysis of the forecast errors produced by predictive models.} We successfully applied the same forecast error analysis for the main type of predictive model (ARIMA) and another type of model used as baseline ($k$NN). This same approach has the potential to be useful for other types of predictive models and for different spatio-temporal problems.

\item \textbf{An open-source Python package designed to work with spatio-temporal data and predictive models.} This package was developed as an implementation of a computational solution to execute the methodology described in this work, but it can be easily adapted and extended for other similar purposes in the field of spatio-temporal analysis.
\end{enumerate}

\section{Future Works}

Here we lay out some of the possible directions for future research in order to extend the reach of this work.

\begin{itemize}
    
    \item Test the capacity and applicability of the proposed methodology with another dataset from a different spatio-temporal phenomenon. Here, we may consider the possibility of traffic flow, which is also characterized by univariate temporal series with spatial characteristics. %TODO why is it different, easier/harder?
    
    \item The calculation of pairwise DTW distances was not a critical element to the performance of the use case scenario, because this compute-intensive process was done only once during the offline phase. However, if we wanted to group evolving time series based on their shape (shape-based clustering), using the default Dynamic Time Warping (DTW) algorithm would not be feasible, because an aggregation of temporal data (extension of the time series) would imply calculating the whole matrix again. Here, we can analyze the possibility of using an incremental process for the DTW distance, that recycles intermediate results of previous calculations for new observations \cite{Oregi2017}.
    
    \item Given that we have considered the division of the domain through a supervised learning techniques, it is possible to see that given the properties of the spatio-temporal data (autocorrelation and non-static) there is a difficulty in finding an ideal number of partitions. Thus, the domain partitioning process may be extended to include non-crisp group relationships, as in the case of fuzzy $k$--medoids \cite{Izakian2015}. Having more than one representative for a given element in the same partitioning scheme may prove useful when considering model composition. For example, it may be the case that two predictive models from different representatives could be merged into a single, more accurate predictive model.

    \item The modular design of the SPTA-TSA framework facilitates the implementation of other families of predictive models and their integration into other aspects of the methodology such as forecast error analysis and query processing. Historically, the ARIMA models have been extensively used in fields such as climate, geophysics, econometrics, among others. However, predicitve models based on neural networks are becoming increasingly prevalent for temporal series in scenarios of data streaming, such as LSTM, RNN, 1DCNN \cite{Shen2020, Torres2021}. Achieving an integration of these models into the existing methodology would represent an important improvement in the proposed solution, both in terms of predictive accuracy and adaptability to other domains.

    
    \item Architectures for TSC
    % Las arquitecturas consideradas en el presente analisis 
    
    \item In the context of the case study presented in this work, the online phase characterized by the query processing did not represent a significant computational effort, the ARIMA models may take some time for training but the prediction of a single temporal series is in the order of the milliseconds. However, more complex models would imply perceivable service times, and then the total response time for a given query can become significant to the user. A natural evolution for our methodology would be to include a multi-objective optimization process, where quality metrics about computational resources and response time would be factored along with quality metrics of predictive quality. In this scenario, the user may then be given a choice between different optimized trade-offs between accuracy and effort.
    % Una evolucion natural para este processamiento de consultas espacio temporales es considerar una funcion de costo. 
\end{itemize}

%"forecast at scale"